{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mms9355/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset silicone (/home/mms9355/.cache/huggingface/datasets/silicone/mrda/1.0.0/af617406c94e3f78da85f7ea74ebfbd3f297a9665cb54adbae305b03bc4442a5)\n",
      "100%|██████████| 3/3 [00:00<00:00, 16.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "ds_raw = load_dataset(\"silicone\", \"mrda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.11226665713639"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for i in ds_raw['train']:\n",
    "    c += len(i['Utterance'])\n",
    "c/len(i)\n",
    "c/len(ds_raw['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "model = BertForSequenceClassification.from_pretrained(\"../models/model_mrda_v2_t1.model\")\n",
    "# model = BertForSequenceClassification.from_pretrained(\"model__v1_t3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Utterance_ID', 'Dialogue_Act', 'Channel_ID', 'Speaker', 'Dialogue_ID', 'Utterance', 'Label', 'Idx'],\n",
       "        num_rows: 83943\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Utterance_ID', 'Dialogue_Act', 'Channel_ID', 'Speaker', 'Dialogue_ID', 'Utterance', 'Label', 'Idx'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Utterance_ID', 'Dialogue_Act', 'Channel_ID', 'Speaker', 'Dialogue_ID', 'Utterance', 'Label', 'Idx'],\n",
       "        num_rows: 15470\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"statement\", \"declarative question\", \"backchannel\", \"follow-me\", \"question\"]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "# Encodes utterances and assigns them classified act labels\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def dataprep(samples):\n",
    "  encoding = tokenizer.encode_plus(samples['Utterance'], add_special_tokens = True,\n",
    "                        max_length = 32,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                        truncation=True,\n",
    "                        padding=\"max_length\"\n",
    "                   )\n",
    "  samples['input_ids'] = encoding['input_ids']\n",
    "  samples['attention_masks'] = encoding['attention_mask']\n",
    "  ls = np.zeros(len(labels))\n",
    "  ls[samples['Label']] = 1\n",
    "  # ls[ACT_LABELS[RAW_ACT_TAGS[samples['damsl_act_tag']]]] = 1\n",
    "  samples['labels'] = ls\n",
    "\n",
    "  return samples\n",
    "\n",
    "# Creates encoded dataset and sets the format to pytorch\n",
    "encoded = ds_raw.map(dataprep)\n",
    "\n",
    "# encoded.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement: 8864\n",
      "declarative question: 2246\n",
      "backchannel: 1961\n",
      "follow-me: 1317\n",
      "question: 1082\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(labels)):\n",
    "    z = 0\n",
    "    for x in encoded['test']['labels']:\n",
    "        l = np.zeros(len(labels)).tolist()\n",
    "        l[i] = 1\n",
    "        if(x == l):\n",
    "            z += 1\n",
    "    print(labels[i] + \": \" + str(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded['test'][5]['Utterance']\n",
    "encoded['test'][5]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933419521654816"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = 0\n",
    "i = 0\n",
    "labeled = np.zeros(len(encoded['test']))\n",
    "for e in encoded['test']:\n",
    "    out = model(e['input_ids'], token_type_ids=None, attention_mask=e['attention_masks'])\n",
    "    logits = out.logits.detach().cpu().numpy()\n",
    "    # print(logits)\n",
    "    labeled[i] = logits.argmax()\n",
    "    if (np.where(e['labels'] == 1)[0][0]  == logits.argmax()):\n",
    "        corrects += 1\n",
    "    i+=1\n",
    "accuracy = corrects/ len(encoded['test'])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and um - um - next to some - some more or less bureaucratic uh - stuff with the - the data collection she's also the wizard in the data collection .\n",
      "Guess: statement\n",
      "Actual: statement\n"
     ]
    }
   ],
   "source": [
    "# Sample classification that doesn't work\n",
    "e = encoded['test'][100]\n",
    "print(e['Utterance'])\n",
    "out = model(e['input_ids'], token_type_ids=None, attention_mask=e['attention_masks'])\n",
    "logits = out.logits.detach().cpu().numpy()\n",
    "print(\"Guess: \" + labels[logits.argmax()])\n",
    "print(\"Actual: \" + labels[np.where(e['labels'] == 1)[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay | um - why don't we get started on that subject anyways ?\n",
      "Guess: statement\n",
      "Actual: statement\n"
     ]
    }
   ],
   "source": [
    "# Example of flawed classification\n",
    "e = encoded['test'][122]\n",
    "print(e['Utterance'])\n",
    "out = model(e['input_ids'], token_type_ids=None, attention_mask=e['attention_masks'])\n",
    "logits = out.logits.detach().cpu().numpy()\n",
    "print(\"Guess: \" + labels[logits.argmax()])\n",
    "print(\"Actual: \" + labels[np.where(e['labels'] == 1)[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what's also nice and for a- - i- - for me in my mind .\n",
      "Guess: statement\n",
      "Actual: statement\n"
     ]
    }
   ],
   "source": [
    "# Sample classification that works #1\n",
    "e = encoded['test'][998]\n",
    "print(e['Utterance'])\n",
    "out = model(e['input_ids'], token_type_ids=None, attention_mask=e['attention_masks'])\n",
    "logits = out.logits.detach().cpu().numpy()\n",
    "print(\"Guess: \" + labels[logits.argmax()])\n",
    "print(\"Actual: \" + labels[np.where(e['labels'] == 1)[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rad !\n",
      "Guess: statement\n",
      "Actual: statement\n"
     ]
    }
   ],
   "source": [
    "# Sample classification that works #2\n",
    "e = encoded['test'][775]\n",
    "print(e['Utterance'])\n",
    "out = model(e['input_ids'], token_type_ids=None, attention_mask=e['attention_masks'])\n",
    "logits = out.logits.detach().cpu().numpy()\n",
    "print(\"Guess: \" + labels[logits.argmax()])\n",
    "print(\"Actual: \" + labels[np.where(e['labels'] == 1)[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement: 8344 : so you could start pulling back .\n",
      "declarative question: 1999 : th- ==\n",
      "backchannel: 2780 : right .\n",
      "follow-me: 1264 : uh ==\n",
      "question: 1083 : full open ?\n"
     ]
    }
   ],
   "source": [
    "swda_df = encoded['test'].to_pandas()\n",
    "swda_df['labels_pred'] = labeled\n",
    "for i in range(0, len(labels)):\n",
    "    content = \"__NONE__\"\n",
    "    df = swda_df[swda_df['labels_pred'] == i]['Utterance']\n",
    "    if(len(df.index) > 0):\n",
    "        rand_sample_ind = random.randint(0, len(df.index)-1)\n",
    "        if(rand_sample_ind >= 0):\n",
    "            content = df.iloc[random.randint(0, len(df.index)-1)]\n",
    "\n",
    "    print_str = labels[i] + \": \" + str(len(df.index)) + \" : \" + content\n",
    "    print(print_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
