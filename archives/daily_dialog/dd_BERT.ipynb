{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mms9355/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset daily_dialog (/home/mms9355/.cache/huggingface/datasets/daily_dialog/train/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
      "100%|██████████| 3/3 [00:00<00:00, 606.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialog', 'act', 'emotion'],\n",
       "        num_rows: 11118\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['dialog', 'act', 'emotion'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialog', 'act', 'emotion'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"daily_dialog\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "labels = [\"dummy\", \"inform\", \"question\", \"directive\", \"commissive\"]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialog', 'act', 'emotion'],\n",
       "        num_rows: 11118\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['dialog', 'act', 'emotion'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialog', 'act', 'emotion'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     dd[d] \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mexchange\u001b[39m\u001b[39m\"\u001b[39m: i, \u001b[39m\"\u001b[39m\u001b[39mdialog\u001b[39m\u001b[39m\"\u001b[39m: batch[\u001b[39m'\u001b[39m\u001b[39mdialog\u001b[39m\u001b[39m'\u001b[39m][d],  \u001b[39m\"\u001b[39m\u001b[39mact\u001b[39m\u001b[39m\"\u001b[39m: batch[\u001b[39m'\u001b[39m\u001b[39mact\u001b[39m\u001b[39m'\u001b[39m][d], \u001b[39m\"\u001b[39m\u001b[39memotion\u001b[39m\u001b[39m\"\u001b[39m: batch[\u001b[39m'\u001b[39m\u001b[39memotion\u001b[39m\u001b[39m'\u001b[39m][d]}\n\u001b[1;32m     14\u001b[0m dd\n\u001b[0;32m---> 15\u001b[0m Dataset\u001b[39m.\u001b[39;49mfrom_dict(dd)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:871\u001b[0m, in \u001b[0;36mDataset.from_dict\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    869\u001b[0m features \u001b[39m=\u001b[39m features \u001b[39mif\u001b[39;00m features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m info\u001b[39m.\u001b[39mfeatures \u001b[39mif\u001b[39;00m info \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    870\u001b[0m arrow_typed_mapping \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 871\u001b[0m \u001b[39mfor\u001b[39;00m col, data \u001b[39min\u001b[39;00m mapping\u001b[39m.\u001b[39;49mitems():\n\u001b[1;32m    872\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (pa\u001b[39m.\u001b[39mArray, pa\u001b[39m.\u001b[39mChunkedArray)):\n\u001b[1;32m    873\u001b[0m         data \u001b[39m=\u001b[39m cast_array_to_feature(data, features[col]) \u001b[39mif\u001b[39;00m features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m data\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "def flatten_list_of_dict(batch):\n",
    "    print(batch)\n",
    "    # return {\"data.a\": [dic[\"act\"] for ex_list_of_dict in batch for dic in ex_list_of_dict]}\n",
    "    # print({\"data.a\": [dic[\"act\"] for ex_list_of_dict in batch[0] for dic in ex_list_of_dict]})\n",
    "    return batch\n",
    "\n",
    "# a = ds['test'].map(flatten_list_of_dict, batched=True, remove_columns=[\"act\"])\n",
    "i = 0\n",
    "batch = ds['test'][i]\n",
    "dd = np.zeros(len(batch['act'])).tolist()\n",
    "\n",
    "for d in range(0, len(batch['act'])):\n",
    "    dd[d] = {\"exchange\": i, \"dialog\": batch['dialog'][d],  \"act\": batch['act'][d], \"emotion\": batch['emotion'][d]}\n",
    "dd\n",
    "Dataset.from_dict(dd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
