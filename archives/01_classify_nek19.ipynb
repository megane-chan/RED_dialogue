{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"models/model_mrda_v2_fewshot_t1.model/\")\n",
    "\n",
    "labels = [\"statement\", \"disruption\", \"backchannel\", \"follow-me\", \"question\"]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick prototyping using sed, TODO change to python re module\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "nek19_chat_df = pd.DataFrame()\n",
    "\n",
    "for session in range(1,9):\n",
    "    f_cmd = cwd + '/data/Project_RED/Cost\\ of\\ Conflict/chat\\ log\\ data/NEK19_{}.txt'.format(session)\n",
    "    f = re.sub(r\"\\\\\", \"\", f_cmd)\n",
    "    f_out_cmd = f_cmd + '.mod'\n",
    "    f_out = re.sub(r\"\\\\\", \"\", f_out_cmd)\n",
    "    cmd = cwd + '/convert_nek.sh {} {}'.format(f_cmd, f_out_cmd)\n",
    "    out = subprocess.run(cmd, shell=True, capture_output=True).stdout\n",
    "\n",
    "    s_df = pd.read_json(f_out)\n",
    "    s_df = s_df.drop(columns=['_id', 'timeZone'])\n",
    "    s_df['creationDateTime'] = s_df['creationDateTime'].apply(parser.parse)\n",
    "    delt = s_df['creationDateTime'].iloc[-1]  - s_df['creationDateTime'].iloc[0]\n",
    "    delt/3\n",
    "    def aux(time):\n",
    "        if(time < s_df['creationDateTime'].iloc[0] + delt/3): \n",
    "            return 0\n",
    "        elif(time < s_df['creationDateTime'].iloc[0] + 2*delt/3):\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    s_df['time'] = s_df['creationDateTime'].map(aux)\n",
    "    s_df['session'] = session\n",
    "    nek19_chat_df = pd.concat([nek19_chat_df, s_df])\n",
    "nek19_chat_df = nek19_chat_df.drop('creationDateTime',axis=1).reset_index(drop=True)\n",
    "nek19_chat = Dataset.from_pandas(nek19_chat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preproccess(samples):\n",
    "    encoding = tokenizer.encode_plus(samples['content'], add_special_tokens = True,\n",
    "                        max_length = 32,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                        truncation=True,\n",
    "                        padding=\"max_length\")\n",
    "        \n",
    "    samples['input_ids'] = encoding['input_ids']\n",
    "    samples['token_type_ids'] = encoding['token_type_ids']\n",
    "    samples['attention_mask'] = encoding['attention_mask']\n",
    "    return samples\n",
    "\n",
    "nek19_chat = nek19_chat.map(preproccess)\n",
    "nek19_chat.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(samples):\n",
    "    out = model(samples['input_ids'], token_type_ids=samples['token_type_ids'], attention_mask=samples['attention_mask'])\n",
    "    logits = out.logits.detach().cpu().numpy()\n",
    "\n",
    "    samples['logits'] = logits[0]\n",
    "    samples['labels_h'] = labels[logits.argmax()-1]\n",
    "    samples['labels'] = logits.argmax()\n",
    "    return samples\n",
    "nek19_chat = nek19_chat.map(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from megans code\n",
    "from pathlib import Path\n",
    "from string import punctuation\n",
    "\n",
    "tran_path = Path('data/Project_RED/Cost of Conflict/transcript data/NEK19/')\n",
    "tran_list = list(tran_path.glob('*.txt'))\n",
    "transcripts = {}\n",
    "time = 0\n",
    "for filepath in tran_list:\n",
    "    name = Path(filepath).stem\n",
    "    with open(filepath,'r',encoding='utf-8') as my_file:\n",
    "        data = my_file.readlines()\n",
    "        clean = []\n",
    "        if \"MAG\" in name:\n",
    "            for line in data:\n",
    "                if line[:1].isalpha() == True and \"Joy \" not in line[:4]:\n",
    "                    clean.append(line)\n",
    "        else:\n",
    "            for line in data:\n",
    "                if \":\" in line and line[:1].isnumeric() == False:\n",
    "                    clean.append(line.strip() + \"&&\" +  str(time))\n",
    "                elif \":\" in line and line[:1].isnumeric() == True:\n",
    "                    time +=1\n",
    "        transcripts[name] = clean\n",
    "\n",
    "def check_trans(word_list, messages):\n",
    "    all_words = {}\n",
    "    counter = {} # includes actual words from conversation\n",
    "    dict_counter = {} # includes words from dictionary\n",
    "    \n",
    "    for message in messages:\n",
    "        content = message.split(\" \")\n",
    "        for word in content:\n",
    "            word = word.strip(punctuation).lower()\n",
    "            if len(word)>1:\n",
    "                if word in all_words:\n",
    "                    all_words[word] += 1\n",
    "                elif word.isalpha() == True:\n",
    "                    all_words[word] = 1\n",
    "                else:\n",
    "                    if word[0].isnumeric() == False:\n",
    "                        for symbol in punctuation:\n",
    "                            if symbol in word:\n",
    "                                split_word = word.split(symbol)\n",
    "                                for section in split_word:\n",
    "                                    if len(section) > 1:\n",
    "                                        if word in all_words:\n",
    "                                            all_words[word] += 1\n",
    "                                        else:\n",
    "                                            if word.isalpha() == True:\n",
    "                                                all_words[word] = 1\n",
    "                for check in word_list:\n",
    "                    find = re.match(check, word)\n",
    "                    if find != None:\n",
    "                        if check[-1] != \"*\":\n",
    "                            if len(word) > find.span()[1]:\n",
    "                                continue\n",
    "                        else:\n",
    "                            if len(word) < len(check):\n",
    "                                continue\n",
    "                        if word not in counter:\n",
    "                            counter[word] = 1\n",
    "                        else:\n",
    "                            counter[word] += 1\n",
    "                        if check not in dict_counter:\n",
    "                            dict_counter[check] = 1\n",
    "                        else:\n",
    "                            dict_counter[check] += 1\n",
    "    return counter, dict_counter, all_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_time = 0\n",
    "nek19_trans_df = pd.DataFrame()\n",
    "for session in transcripts:\n",
    "   s_df = pd.DataFrame.from_dict(transcripts[session])\n",
    "   def trans_proccess(c): \n",
    "\n",
    "      global g_time\n",
    "      x=c[0].strip()\n",
    "      # print(x)\n",
    "      try:\n",
    "         speaker = re.search(r\"^[^:]*:\\s*\", x).group()[:-2]\n",
    "      except:\n",
    "         speaker = \"\"\n",
    "      try:\n",
    "         content = re.search(r\":(.*)&&\", x).group()[1:-2]\n",
    "      except:\n",
    "         content = \"\"\n",
    "      try:\n",
    "         time = int(re.search(r\"&&.*\", x).group()[2:])\n",
    "         g_time = time\n",
    "      except:\n",
    "         time = -1\n",
    "\n",
    "      if(speaker == \"\" and content == \"\"):\n",
    "         speaker = None\n",
    "         content = None\n",
    "\n",
    "      row = pd.Series()\n",
    "\n",
    "      row['speaker'] = speaker\n",
    "      row['content'] = content\n",
    "      row['block'] = time-last_time \n",
    "      row['session'] = session\n",
    "      return row\n",
    "   nek19_trans_df = pd.concat([nek19_trans_df, s_df.apply(lambda x: trans_proccess(x), axis=1)])\n",
    "   last_time = g_time\n",
    "nek19_trans_df = nek19_trans_df.dropna()\n",
    "nek19_trans_df = nek19_trans_df[nek19_trans_df['block'] >= 0].reset_index(drop=True)\n",
    "nek19_trans_df['block'] = (nek19_trans_df['block'] / nek19_trans_df['block'].max() * 10).apply(int)\n",
    "nek19_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize\n",
    "\n",
    "for session in transcripts:\n",
    "    s = nek19_trans_df[nek19_trans_df['session'] == session]\n",
    "    delt = s['block'].max()\n",
    "    s['time'] = 2\n",
    "    s.loc[s['block'] < 2*delt/3, 'time']= 1\n",
    "    s.loc[s['block'] < delt/3, 'time']= 0\n",
    "    nek19_trans_df.loc[nek19_trans_df['session'] == session,'time'] = s['time']\n",
    "# nek19_trans_df =nek19_trans_df.drop('block', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek19_trans_df['content'].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek19_trans = Dataset.from_pandas(nek19_trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek19_trans = nek19_trans.map(preproccess)\n",
    "nek19_trans.set_format('torch')\n",
    "\n",
    "nek19_trans = nek19_trans.map(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy by taking a random sample of 20 (10 translated, 10 msgs)\n",
    "import random \n",
    "from operator import itemgetter\n",
    "\n",
    "n = 10\n",
    "trans_sample_ind = random.sample(range(0, len(nek19_trans)), n)\n",
    "chat_sample_ind = random.sample(range(0, len(nek19_chat)), n)\n",
    "samples = pd.DataFrame(columns=['content', 'model_label', 'human_label', 'source'])\n",
    "trans_sample = itemgetter(*trans_sample_ind)(nek19_trans)\n",
    "chat_sample = itemgetter(*chat_sample_ind)(nek19_chat)\n",
    "samples = pd.DataFrame(columns=[\"source\", \"content\", \"label\"])\n",
    "\n",
    "for t in trans_sample:\n",
    "    samples.loc[len(samples.index)] = [\"spoken\", t['content'], t['labels_h']]\n",
    "\n",
    "for c in chat_sample:\n",
    "    samples.loc[len(samples.index)] = [\"chat\", c['content'], c['labels_h']]\n",
    "\n",
    "print(\"Unique Labels in Set: \" + str(len(pd.unique(samples['label']))))\n",
    "samples.to_csv('samples.csv')\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek19_trans_df = nek19_trans.to_pandas()\n",
    "for i in range(0, len(labels)):\n",
    "    content = \"__NONE__\"\n",
    "    df = nek19_trans_df[nek19_trans_df['labels'] == i]['content']\n",
    "    if(len(df.index) > 0):\n",
    "        rand_sample_ind = random.randint(0, len(df.index)-1)\n",
    "        if(rand_sample_ind >= 0):\n",
    "            content = df.iloc[random.randint(0, len(df.index)-1)]\n",
    "\n",
    "    print_str = labels[i] + \": \" + str(len(df.index)) + \" : \" + content\n",
    "    print(print_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek19_trans_df = nek19_trans.to_pandas()\n",
    "for i in range(0, len(labels)):\n",
    "    content = \"__NONE__\"\n",
    "    df = nek19_trans_df[nek19_trans_df['labels'] == i]['content']\n",
    "    if(len(df.index) > 0):\n",
    "        rand_sample_ind = random.randint(0, len(df.index)-1)\n",
    "        if(rand_sample_ind >= 0):\n",
    "            content = df.iloc[random.randint(0, len(df.index)-1)]\n",
    "\n",
    "    print_str = labels[i] + \": \" + str(len(df.index)) + \" : \" + content\n",
    "    print(print_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in perf data for NEK19\n",
    "perf_df = pd.read_csv('data/Project_RED/calculated performance data/NEKMTSCalcs.csv')\n",
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "n = len(transcripts.keys())\n",
    "fig, axs = plt.subplots(2,2)\n",
    "\n",
    "fig.set_size_inches(12,10)\n",
    "session = 1\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Time', ylabel='Count', title=\"NEK19 Session: \" + str(session))\n",
    "    ax.axes.xaxis.set_ticklabels([])\n",
    "    df = nek19_trans_df[nek19_trans_df['session'] == str(session)]\n",
    "    bs = range(0, len(df['block'].unique()))\n",
    "    distss = []\n",
    "    for i in range(0, len(labels)):\n",
    "        #each block is approx 1-4 mins\n",
    "        dists = []\n",
    "        for b in bs:\n",
    "            within_block = df[df['block'] == b]\n",
    "            dists = dists + [len(within_block[within_block['labels'] == i].index)]\n",
    "        distss = distss + [dists]\n",
    "        # plt.title(labels[i] + \": \" + str(session))\n",
    "        # TODO: Volume graph with evetry __ timepoints; have 10ish points\n",
    "\n",
    "    ax.stackplot(bs, distss)\n",
    "    session += 1\n",
    "fig.legend(labels)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from labellines import labelLine, labelLines\n",
    "# fig, axs = plt.subplots(3,2)\n",
    "bs = range(0, len(nek19_trans_df['block'].unique()))\n",
    "i=0\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(24,10)\n",
    "spec = mpl.gridspec.GridSpec(ncols=3, nrows=2)\n",
    "def perf_gradient(score):\n",
    "    return np.array([1, 0, 0]) * (1-score) + np.array([0, 1, 0]) * score\n",
    "axs = [\n",
    "    fig.add_subplot(spec[0, 0]),\n",
    "    fig.add_subplot(spec[0, 1]),\n",
    "    fig.add_subplot(spec[0, 2]),\n",
    "    fig.add_subplot(spec[1, 0]),\n",
    "    fig.add_subplot(spec[1, 1]),\n",
    "]\n",
    "for ax in axs:\n",
    "    for session in range(1, n+1):\n",
    "        ax.set(xlabel='Time', ylabel='Count', title=(labels[i]))\n",
    "        ax.axes.xaxis.set_ticklabels([])\n",
    "        matched_label = nek19_trans_df[nek19_trans_df['labels'] == i]\n",
    "        df = matched_label[matched_label['session'] == str(session)]\n",
    "        dist = []\n",
    "        for b in bs:\n",
    "            within_block = df[df['block'] == b]\n",
    "            dist = dist + [len(within_block.index)]\n",
    "        ax.plot(bs, dist, label=str(session), color=perf_gradient(perf_df['MTSPerf'].iloc[session-1]))\n",
    "    i+=1\n",
    "    labelLines(ax.get_lines(), yoffsets=0.00, align=False, zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results to csv\n",
    "export_df = nek19_trans_df[['speaker', 'content', 'block', 'session', 'labels', 'labels_h']]\n",
    "export_df.to_csv('results/nek19_trans_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
