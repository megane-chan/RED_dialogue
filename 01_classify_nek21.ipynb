{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"models/model_mrda_v2_t1.model/\")\n",
    "\n",
    "labels = [\"statement\", \"disruption\", \"backchannel\", \"follow-me\", \"question\"]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick prototyping using sed, TODO change to python re module\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "nek21_chat_df = pd.DataFrame()\n",
    "session_numbers = list(range(1,20))\n",
    "session_numbers.remove(2)\n",
    "for session in session_numbers:\n",
    "    f_cmd = cwd + \"/data/Project_RED/Cost\\ of\\ Conflict/chat\\ log\\ data/NEK21/{:02d}.csv\".format(session)\n",
    "    f = re.sub(r\"\\\\\", \"\", f_cmd)\n",
    "    f_out_cmd = f_cmd + '.mod'\n",
    "    f_out = re.sub(r\"\\\\\", \"\", f_out_cmd)\n",
    "    cmd = cwd + '/convert_nek21.sh {} {}'.format(f_cmd, f_out_cmd)\n",
    "    out = subprocess.run(cmd, shell=True, capture_output=True).stdout\n",
    "    s_df = pd.read_csv(f_out)\n",
    "    s_df = s_df.drop(columns=['_id', 'timeZone'])\n",
    "    s_df['creationDateTime'] = s_df['creationDateTime'].apply(parser.parse)\n",
    "    delt = s_df['creationDateTime'].iloc[-1]  - s_df['creationDateTime'].iloc[0]\n",
    "    num_blocks = 3\n",
    "    def aux(time):\n",
    "        v = int(((time - s_df['creationDateTime'].iloc[0])/delt) * num_blocks)\n",
    "        if(v == num_blocks): v = num_blocks-1\n",
    "\n",
    "        return v\n",
    "    s_df['time'] = s_df['creationDateTime'].map(aux)\n",
    "    s_df['session'] = session\n",
    "    nek21_chat_df = pd.concat([nek21_chat_df, s_df])\n",
    "nek21_chat_df = nek21_chat_df.drop('creationDateTime',axis=1).reset_index(drop=True)\n",
    "nek21_chat = Dataset.from_pandas(nek21_chat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek21_chat['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preproccess(samples):\n",
    "    encoding = tokenizer.encode_plus(samples['content'], add_special_tokens = True,\n",
    "                        max_length = 32,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                        truncation=True,\n",
    "                        padding=\"max_length\")\n",
    "        \n",
    "    samples['input_ids'] = encoding['input_ids']\n",
    "    samples['token_type_ids'] = encoding['token_type_ids']\n",
    "    samples['attention_mask'] = encoding['attention_mask']\n",
    "    return samples\n",
    "\n",
    "nek21_chat = nek21_chat.map(preproccess)\n",
    "nek21_chat.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "\n",
    "def classify(samples):\n",
    "    out = model(samples['input_ids'], token_type_ids=samples['token_type_ids'], attention_mask=samples['attention_mask'])\n",
    "    logits = out.logits.detach().cpu().numpy()\n",
    "\n",
    "    samples['logits'] = logits[0]\n",
    "    # samples['labels_h'] = labels[logits.argmax()]\n",
    "    samples['labels_h'] = labels[logits.argmax()]\n",
    "    samples['labels'] = logits.argmax()\n",
    "    if(re.match(\"^.*lease confirm when.*$\", samples['content'])):\n",
    "        samples['labels'] = tensor(0)\n",
    "        samples['labels_h'] = 'dummy'\n",
    "    return samples\n",
    "nek21_chat = nek21_chat.map(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek21_chat[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from megans code\n",
    "from pathlib import Path\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "tran_path = Path('data/Project_RED/Cost of Conflict/transcript data/NEK21/')\n",
    "tran_list = list(tran_path.glob('*.txt'))\n",
    "transcripts = {}\n",
    "time = 0\n",
    "for filepath in tran_list:\n",
    "    name = Path(filepath).stem\n",
    "    with open(filepath,'r',encoding='utf-8') as my_file:\n",
    "        data = my_file.readlines()\n",
    "        clean = []\n",
    "        if \"MAG\" in name:\n",
    "            for line in data:\n",
    "                if line[:1].isalpha() == True and \"Joy \" not in line[:4]:\n",
    "                    clean.append(line)\n",
    "        else:\n",
    "            for line in data:\n",
    "                if \":\" in line and line[:1].isnumeric() == False:\n",
    "                    clean.append(line.strip() + \"&&\" +  str(time))\n",
    "                elif \":\" in line and line[:1].isnumeric() == True:\n",
    "                    time +=1\n",
    "        transcripts[name] = clean\n",
    "\n",
    "def check_trans(word_list, messages):\n",
    "    all_words = {}\n",
    "    counter = {} # includes actual words from conversation\n",
    "    dict_counter = {} # includes words from dictionary\n",
    "    \n",
    "    for message in messages:\n",
    "        content = message.split(\" \")\n",
    "        for word in content:\n",
    "            word = word.strip(punctuation).lower()\n",
    "            if len(word)>1:\n",
    "                if word in all_words:\n",
    "                    all_words[word] += 1\n",
    "                elif word.isalpha() == True:\n",
    "                    all_words[word] = 1\n",
    "                else:\n",
    "                    if word[0].isnumeric() == False:\n",
    "                        for symbol in punctuation:\n",
    "                            if symbol in word:\n",
    "                                split_word = word.split(symbol)\n",
    "                                for section in split_word:\n",
    "                                    if len(section) > 1:\n",
    "                                        if word in all_words:\n",
    "                                            all_words[word] += 1\n",
    "                                        else:\n",
    "                                            if word.isalpha() == True:\n",
    "                                                all_words[word] = 1\n",
    "                for check in word_list:\n",
    "                    find = re.match(check, word)\n",
    "                    if find != None:\n",
    "                        if check[-1] != \"*\":\n",
    "                            if len(word) > find.span()[1]:\n",
    "                                continue\n",
    "                        else:\n",
    "                            if len(word) < len(check):\n",
    "                                continue\n",
    "                        if word not in counter:\n",
    "                            counter[word] = 1\n",
    "                        else:\n",
    "                            counter[word] += 1\n",
    "                        if check not in dict_counter:\n",
    "                            dict_counter[check] = 1\n",
    "                        else:\n",
    "                            dict_counter[check] += 1\n",
    "    return counter, dict_counter, all_words\n",
    "\n",
    "# session = transcripts[list(transcripts.keys())[0]]\n",
    "last_time = 0\n",
    "nek21_trans_df = pd.DataFrame()\n",
    "for session in transcripts:\n",
    "   s_df = pd.DataFrame.from_dict(transcripts[session])\n",
    "   def trans_proccess(c): \n",
    "\n",
    "      global g_time\n",
    "      x=c[0].strip()\n",
    "      # print(x)\n",
    "      try:\n",
    "         speaker = re.search(r\"^[^:]*:\\s*\", x).group()[:-2]\n",
    "      except:\n",
    "         speaker = \"\"\n",
    "      try:\n",
    "         content = re.search(r\":(.*)&&\", x).group()[1:-2]\n",
    "      except:\n",
    "         content = \"\"\n",
    "      try:\n",
    "         time = int(re.search(r\"&&.*\", x).group()[2:])\n",
    "         g_time = time\n",
    "      except:\n",
    "         time = -1\n",
    "\n",
    "      if(speaker == \"\" and content == \"\"):\n",
    "         speaker = None\n",
    "         content = None\n",
    "\n",
    "      row = pd.Series()\n",
    "\n",
    "      row['speaker'] = speaker\n",
    "      row['content'] = content\n",
    "      row['block'] = time-last_time \n",
    "      row['session'] = session\n",
    "      return row\n",
    "   nek21_trans_df = pd.concat([nek21_trans_df, s_df.apply(lambda x: trans_proccess(x), axis=1)])\n",
    "   last_time = g_time\n",
    "   # print(str(session) + \": \" + str(last_time))\n",
    "nek21_trans_df = nek21_trans_df.dropna()\n",
    "nek21_trans_df = nek21_trans_df[nek21_trans_df['block'] >= 0].reset_index(drop=True)\n",
    "import math\n",
    "nek21_trans_df['block'] = (nek21_trans_df['block'] / nek21_trans_df['block'].max() * 10).apply(math.floor)\n",
    "nek21_trans_df['session'] = nek21_trans_df['session'].astype('int')\n",
    "nek21_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from megans code\n",
    "from pathlib import Path\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "tran_path_mag = Path('data/Project_RED/Cost of Conflict/transcript data/NEK21_MAG/')\n",
    "tran_list_mag = list(tran_path.glob('*.txt'))\n",
    "transcripts_mag = {}\n",
    "time = 0\n",
    "for filepath in tran_list_mag:\n",
    "    name = Path(filepath).stem\n",
    "    with open(filepath,'r',encoding='utf-8') as my_file:\n",
    "        data = my_file.readlines()\n",
    "        clean = []\n",
    "        for line in data:\n",
    "            if \":\" in line and line[:1].isnumeric() == False:\n",
    "                clean.append(line.strip() + \"&&\" + str(time))\n",
    "            elif \":\" in line and line[:1].isnumeric() == True:\n",
    "                time += 1\n",
    "        transcripts_mag[name] = clean\n",
    "\n",
    "def check_trans(word_list, messages):\n",
    "    all_words = {}\n",
    "    counter = {} # includes actual words from conversation\n",
    "    dict_counter = {} # includes words from dictionary\n",
    "    \n",
    "    for message in messages:\n",
    "        content = message.split(\" \")\n",
    "        for word in content:\n",
    "            word = word.strip(punctuation).lower()\n",
    "            if len(word)>1:\n",
    "                if word in all_words:\n",
    "                    all_words[word] += 1\n",
    "                elif word.isalpha() == True:\n",
    "                    all_words[word] = 1\n",
    "                else:\n",
    "                    if word[0].isnumeric() == False:\n",
    "                        for symbol in punctuation:\n",
    "                            if symbol in word:\n",
    "                                split_word = word.split(symbol)\n",
    "                                for section in split_word:\n",
    "                                    if len(section) > 1:\n",
    "                                        if word in all_words:\n",
    "                                            all_words[word] += 1\n",
    "                                        else:\n",
    "                                            if word.isalpha() == True:\n",
    "                                                all_words[word] = 1\n",
    "                for check in word_list:\n",
    "                    find = re.match(check, word)\n",
    "                    if find != None:\n",
    "                        if check[-1] != \"*\":\n",
    "                            if len(word) > find.span()[1]:\n",
    "                                continue\n",
    "                        else:\n",
    "                            if len(word) < len(check):\n",
    "                                continue\n",
    "                        if word not in counter:\n",
    "                            counter[word] = 1\n",
    "                        else:\n",
    "                            counter[word] += 1\n",
    "                        if check not in dict_counter:\n",
    "                            dict_counter[check] = 1\n",
    "                        else:\n",
    "                            dict_counter[check] += 1\n",
    "    return counter, dict_counter, all_words\n",
    "\n",
    "session_mag = transcripts_mag[list(transcripts_mag.keys())[0]]\n",
    "last_time = 0\n",
    "mag21_trans_df = pd.DataFrame()\n",
    "for session_mag in transcripts_mag:\n",
    "   s_df = pd.DataFrame.from_dict(transcripts_mag[session_mag])\n",
    "   def trans_proccess(c): \n",
    "\n",
    "      global g_time\n",
    "      x=c[0].strip()\n",
    "      # print(x)\n",
    "      try:\n",
    "         speaker = re.search(r\"^[^:]*:\\s*\", x).group()[:-2]\n",
    "      except:\n",
    "         speaker = \"\"\n",
    "      try:\n",
    "         content = re.search(r\":(.*)&&\", x).group()[1:-2]\n",
    "      except:\n",
    "         content = \"\"\n",
    "      try:\n",
    "         time = int(re.search(r\"&&.*\", x).group()[2:])\n",
    "         g_time = time\n",
    "      except:\n",
    "         time = -1\n",
    "\n",
    "      if(speaker == \"\" and content == \"\"):\n",
    "         speaker = None\n",
    "         content = None\n",
    "\n",
    "      row = pd.Series()\n",
    "\n",
    "      row['speaker'] = speaker\n",
    "      row['content'] = content\n",
    "      row['block'] = time-last_time \n",
    "      row['session'] = session\n",
    "      return row\n",
    "   mag21_trans_df = pd.concat([mag21_trans_df, s_df.apply(lambda x: trans_proccess(x), axis=1)])\n",
    "   last_time = g_time\n",
    "   # print(str(session) + \": \" + str(last_time))\n",
    "# def strip_mag(s):\n",
    "#     return re.sub(\"[^0-9]\", \"\", s)\n",
    "mag21_trans_df['session'] = mag21_trans_df['session'].astype(int)\n",
    "mag21_trans_df = mag21_trans_df.dropna()\n",
    "mag21_trans_df = mag21_trans_df[mag21_trans_df['block'] >= 0].reset_index(drop=True)\n",
    "import math\n",
    "mag21_trans_df['block'] = (mag21_trans_df['block'] / mag21_trans_df['block'].max() * 10).apply(math.floor)\n",
    "mag21_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mag21_trans_df['session'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mag21_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize\n",
    "\n",
    "for session in transcripts:\n",
    "    s = nek21_trans_df[nek21_trans_df['session'] == session]\n",
    "    delt = s['block'].max()\n",
    "    s['time'] = 2\n",
    "    s.loc[s['block'] < 2*delt/3, 'time']= 1\n",
    "    s.loc[s['block'] < delt/3, 'time']= 0\n",
    "    nek21_trans_df.loc[nek21_trans_df['session'] == session,'time'] = s['time']\n",
    "# nek21_trans_df =nek21_trans_df.drop('block', axis=1)\n",
    "\n",
    "for session_mag in transcripts_mag:\n",
    "    s = mag21_trans_df[mag21_trans_df['session'] == session_mag]\n",
    "    delt = s['block'].max()\n",
    "    mag21_trans_df.loc[mag21_trans_df['session'] == session_mag,'time'] = s['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag21_trans_df['time'] = ((mag21_trans_df['block'] / 11) * 3).apply(math.floor)\n",
    "nek21_trans_df['time'] = ((nek21_trans_df['block'] / 11) * 3).apply(math.floor)\n",
    "mag21_trans_df[mag21_trans_df['block'] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek21_trans = Dataset.from_pandas(nek21_trans_df)\n",
    "mag21_trans = Dataset.from_pandas(mag21_trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek21_trans = nek21_trans.map(preproccess)\n",
    "nek21_trans.set_format('torch')\n",
    "\n",
    "nek21_trans = nek21_trans.map(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag21_trans = mag21_trans.map(preproccess)\n",
    "mag21_trans.set_format('torch')\n",
    "\n",
    "mag21_trans = mag21_trans.map(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag21_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek21_trans[3008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy by taking a random sample of 20 (10 translated, 10 msgs)\n",
    "\n",
    "import random \n",
    "from operator import itemgetter\n",
    "\n",
    "n = 10\n",
    "trans_sample_ind = random.sample(range(0, len(nek21_trans)), n)\n",
    "chat_sample_ind = random.sample(range(0, len(nek21_chat)), n)\n",
    "samples = pd.DataFrame(columns=['content', 'model_label', 'human_label', 'source'])\n",
    "# pd.concat([\n",
    "#     pd.DataFrame.from_dict(nek21_trans[trans_sample]),\n",
    "#     pd.DataFrame.from_dict(nek21_chat[chat_sample])\n",
    "#                  ])\n",
    "\n",
    "trans_sample = itemgetter(*trans_sample_ind)(nek21_trans)\n",
    "chat_sample = itemgetter(*chat_sample_ind)(nek21_chat)\n",
    "samples = pd.DataFrame(columns=[\"source\", \"content\", \"label\"])\n",
    "\n",
    "for t in trans_sample:\n",
    "    samples.loc[len(samples.index)] = [\"spoken\", t['content'], t['labels_h']]\n",
    "\n",
    "for c in chat_sample:\n",
    "    samples.loc[len(samples.index)] = [\"chat\", c['content'], c['labels_h']]\n",
    "\n",
    "print(\"Unique Labels in Set: \" + str(len(pd.unique(samples['label']))))\n",
    "samples.to_csv('samples.csv')\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek21_trans_df = nek21_trans.to_pandas()\n",
    "for i in range(0, len(labels)):\n",
    "    content = \"__NONE__\"\n",
    "    df = nek21_trans_df[nek21_trans_df['labels'] == i]['content']\n",
    "    if(len(df.index) > 0):\n",
    "        rand_sample_ind = random.randint(0, len(df.index)-1)\n",
    "        if(rand_sample_ind >= 0):\n",
    "            content = df.iloc[random.randint(0, len(df.index)-1)]\n",
    "\n",
    "    print_str = labels[i] + \": \" + str(len(df.index)) + \" : \" + content\n",
    "    print(print_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek21_trans_df = nek21_trans.to_pandas()\n",
    "for i in range(0, len(labels)):\n",
    "    content = \"__NONE__\"\n",
    "    df = nek21_trans_df[nek21_trans_df['labels'] == i]['content']\n",
    "    if(len(df.index) > 0):\n",
    "        rand_sample_ind = random.randint(0, len(df.index)-1)\n",
    "        if(rand_sample_ind >= 0):\n",
    "            content = df.iloc[random.randint(0, len(df.index)-1)]\n",
    "\n",
    "    print_str = labels[i] + \": \" + str(len(df.index)) + \" : \" + content\n",
    "    print(print_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO NEK21\n",
    "# perf_df = pd.read_csv('data/Project_RED/calculated performance data/NEKMTSCalcs.csv')\n",
    "# perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek21_trans_df[nek21_trans_df['block']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "n = len(transcripts.keys())\n",
    "fig, axs = plt.subplots(5,4)\n",
    "\n",
    "fig.set_size_inches(24,20)\n",
    "fig.suptitle(\"Transcripts\")\n",
    "session = 1\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Time', ylabel='Count', title=\"NEK21 Session: \" + str(session))\n",
    "    ax.axes.xaxis.set_ticklabels([])\n",
    "    df = nek21_trans_df[nek21_trans_df['session'] == (session)]\n",
    "    bs = range(0, len(df['block'].unique()))\n",
    "    distss = []\n",
    "    for i in range(0, len(labels)):\n",
    "        #each block is approx <5 mins\n",
    "        dists = []\n",
    "        for b in bs:\n",
    "            within_block = df[df['block'] == b]\n",
    "            # print(within_block)\n",
    "            dists = dists + [len(within_block[within_block['labels'] == i].index)]\n",
    "        distss = distss + [dists]\n",
    "\n",
    "    ax.stackplot(bs, distss)\n",
    "    session += 1\n",
    "fig.legend(labels)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nek21_chat_df=nek21_chat.to_pandas()\n",
    "nek21_chat_df['block'] = nek21_chat_df['time']\n",
    "\n",
    "n = len(transcripts.keys())\n",
    "fig, axs = plt.subplots(5,4)\n",
    "\n",
    "fig.set_size_inches(24,20)\n",
    "fig.suptitle(\"Chat\")\n",
    "session = 1\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Time', ylabel='Count', title=\"NEK21 Session: \" + str(session))\n",
    "    ax.axes.xaxis.set_ticklabels([])\n",
    "    df = nek21_chat_df[nek21_chat_df['session'] == (session)]\n",
    "    bs = range(0, len(df['block'].unique()))\n",
    "    distss = []\n",
    "    for i in range(0, len(labels)):\n",
    "        #each block is approx <5 mins\n",
    "        dists = []\n",
    "        for b in bs:\n",
    "            within_block = df[df['block'] == b]\n",
    "            dists = dists + [len(within_block[within_block['labels'] == i].index)]\n",
    "        distss = distss + [dists]\n",
    "\n",
    "    ax.stackplot(bs, distss)\n",
    "    session += 1\n",
    "fig.legend(labels)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from labellines import labelLine, labelLines\n",
    "# fig, axs = plt.subplots(3,2)\n",
    "i=0\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(24,10)\n",
    "fig.suptitle(\"Transcripts\")\n",
    "spec = mpl.gridspec.GridSpec(ncols=3, nrows=2)\n",
    "bs = range(0, len(nek21_trans_df['block'].unique()))\n",
    "def perf_gradient(score):\n",
    "    return np.array([1, 0, 0]) * (1-score) + np.array([0, 1, 0]) * score\n",
    "axs = [\n",
    "    fig.add_subplot(spec[0, 0]),\n",
    "    fig.add_subplot(spec[0, 1]),\n",
    "    fig.add_subplot(spec[0, 2]),\n",
    "    fig.add_subplot(spec[1, 0]),\n",
    "    fig.add_subplot(spec[1, 1]),\n",
    "]\n",
    "for ax in axs:\n",
    "    for session in range(1, n+1):\n",
    "        session_df = nek21_trans_df[nek21_trans_df['session'] == session]\n",
    "        ax.set(xlabel='Time', ylabel='Count', title=(labels[i]))\n",
    "        ax.axes.xaxis.set_ticklabels([])\n",
    "        matched_label = nek21_trans_df[nek21_trans_df['labels'] == i]\n",
    "        df = matched_label[matched_label['session'] == (session)]\n",
    "        dist = []\n",
    "        for b in bs:\n",
    "            within_block = df[df['block'] == b]\n",
    "            dist = dist + [len(within_block.index)]\n",
    "        # ax.plot(bs, dist, label=str(session), color=perf_gradient(perf_df['MTSPerf'].iloc[session-1]))\n",
    "        ax.plot(bs, dist, label=str(session))\n",
    "    i+=1\n",
    "    labelLines(ax.get_lines(), yoffsets=0.00, align=False, zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib as mpl\n",
    "from labellines import labelLine, labelLines\n",
    "# fig, axs = plt.subplots(3,2)\n",
    "i=0\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(24,10)\n",
    "fig.suptitle(\"Chats\")\n",
    "spec = mpl.gridspec.GridSpec(ncols=3, nrows=2)\n",
    "bs = range(0, len(nek21_chat_df['block'].unique()))\n",
    "def perf_gradient(score):\n",
    "    return np.array([1, 0, 0]) * (1-score) + np.array([0, 1, 0]) * score\n",
    "axs = [\n",
    "    fig.add_subplot(spec[0, 0]),\n",
    "    fig.add_subplot(spec[0, 1]),\n",
    "    fig.add_subplot(spec[0, 2]),\n",
    "    fig.add_subplot(spec[1, 0]),\n",
    "    fig.add_subplot(spec[1, 1]),\n",
    "]\n",
    "for ax in axs:\n",
    "    for session in range(1, n+1):\n",
    "        session_df = nek21_chat_df[nek21_chat_df['session'] == session]\n",
    "        ax.set(xlabel='Time', ylabel='Count', title=(labels[i]))\n",
    "        ax.axes.xaxis.set_ticklabels([])\n",
    "        matched_label = nek21_chat_df[nek21_chat_df['labels'] == i]\n",
    "        df = matched_label[matched_label['session'] == (session)]\n",
    "        dist = []\n",
    "        for b in bs:\n",
    "            within_block = df[df['block'] == b]\n",
    "            dist = dist + [len(within_block.index)]\n",
    "        # ax.plot(bs, dist, label=str(session), color=perf_gradient(perf_df['MTSPerf'].iloc[session-1]))\n",
    "        ax.plot(bs, dist, label=str(session))\n",
    "    i+=1\n",
    "    labelLines(ax.get_lines(), yoffsets=0.00, align=False, zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib as mpl\n",
    "from labellines import labelLine, labelLines\n",
    "# fig, axs = plt.subplots(3,2)\n",
    "i=0\n",
    "fig, axs = plt.subplots(5,4)\n",
    "fig.set_size_inches(24,10)\n",
    "fig.suptitle(\"Transcripts\")\n",
    "spec = mpl.gridspec.GridSpec(ncols=5, nrows=4)\n",
    "bs = range(0, len(nek21_trans_df['block'].unique()))\n",
    "def perf_gradient(score):\n",
    "    return np.array([1, 0, 0]) * (1-score) + np.array([0, 1, 0]) * score\n",
    "for z in range(0,4):\n",
    "    i=0\n",
    "    for y in range(0,5):\n",
    "        ax = axs[y][z]\n",
    "        for session in range(1+4*z, 1+4*(z+1)):\n",
    "            session_df = nek21_trans_df[nek21_trans_df['session'] == session]\n",
    "            ax.set(xlabel='Time', ylabel='Count', title=(labels[i]))\n",
    "            ax.axes.xaxis.set_ticklabels([])\n",
    "            matched_label = nek21_trans_df[nek21_trans_df['labels'] == i]\n",
    "            df = matched_label[matched_label['session'] == (session)]\n",
    "            dist = []\n",
    "            for b in bs:\n",
    "                within_block = df[df['block'] == b]\n",
    "                dist = dist + [len(within_block.index)]\n",
    "            # ax.plot(bs, dist, label=str(session), color=perf_gradient(perf_df['MTSPerf'].iloc[session-1]))\n",
    "            ax.plot(bs, dist, label=str(session))\n",
    "        i+=1\n",
    "        labelLines(ax.get_lines(), yoffsets=0.00, align=False, zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib as mpl\n",
    "from labellines import labelLine, labelLines\n",
    "# fig, axs = plt.subplots(3,2)\n",
    "i=0\n",
    "fig, axs = plt.subplots(5,4)\n",
    "fig.set_size_inches(24,10)\n",
    "fig.suptitle(\"Chats\")\n",
    "spec = mpl.gridspec.GridSpec(ncols=5, nrows=4)\n",
    "bs = range(0, len(nek21_chat_df['block'].unique()))\n",
    "def perf_gradient(score):\n",
    "    return np.array([1, 0, 0]) * (1-score) + np.array([0, 1, 0]) * score\n",
    "for z in range(0,4):\n",
    "    i=0\n",
    "    for y in range(0,5):\n",
    "        ax = axs[y][z]\n",
    "        for session in range(1+4*z, 1+4*(z+1)):\n",
    "            session_df = nek21_chat_df[nek21_chat_df['session'] == session]\n",
    "            ax.set(xlabel='Time', ylabel='Count', title=(labels[i]))\n",
    "            ax.axes.xaxis.set_ticklabels([])\n",
    "            matched_label = nek21_chat_df[nek21_chat_df['labels'] == i]\n",
    "            df = matched_label[matched_label['session'] == (session)]\n",
    "            dist = []\n",
    "            for b in bs:\n",
    "                within_block = df[df['block'] == b]\n",
    "                dist = dist + [len(within_block.index)]\n",
    "            # ax.plot(bs, dist, label=str(session), color=perf_gradient(perf_df['MTSPerf'].iloc[session-1]))\n",
    "            ax.plot(bs, dist, label=str(session))\n",
    "        i+=1\n",
    "        labelLines(ax.get_lines(), yoffsets=0.00, align=False, zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nek21_trans_df[nek21_trans_df['labels'] == (3)].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results to csv\n",
    "export_df1 = nek21_trans_df[['speaker', 'content', 'block', 'session', 'labels', 'labels_h']]\n",
    "export_df1.to_csv('results/nek21_trans_df.csv')\n",
    "export_df2 = nek21_chat_df[['sender','recipient', 'content', 'block', 'session', 'labels', 'labels_h']]\n",
    "export_df2.to_csv('results/nek21_chat_df.csv')\n",
    "export_df3 = mag21_trans_df[['speaker', 'content', 'block', 'session', 'labels', 'labels_h']]\n",
    "export_df3.to_csv('results/mag21_trans_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
